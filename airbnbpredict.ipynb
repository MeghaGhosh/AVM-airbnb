{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeghaGhosh/AVM-airbnb/blob/master/airbnbpredict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5dSyRqz1pgR",
        "colab_type": "code",
        "outputId": "8c57d6d4-1f5f-4ac0-dbb7-d60b21864de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFk1x6ot2nL-",
        "colab_type": "code",
        "outputId": "f658b015-23a4-428f-ce10-17b257558aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KybTnX32qmh",
        "colab_type": "code",
        "outputId": "fc7ec244-616d-45b0-9f37-cae293a73345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd 'My Drive'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhvVrfu5247j",
        "colab_type": "code",
        "outputId": "41dc0f80-2496-4f7e-be7e-27a27dc9f243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv('AB_NYC_2019.csv')\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>host_id</th>\n",
              "      <th>host_name</th>\n",
              "      <th>neighbourhood_group</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>room_type</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>last_review</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2539</td>\n",
              "      <td>Clean &amp; quiet apt home by the park</td>\n",
              "      <td>2787</td>\n",
              "      <td>John</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Kensington</td>\n",
              "      <td>40.64749</td>\n",
              "      <td>-73.97237</td>\n",
              "      <td>Private room</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2018-10-19</td>\n",
              "      <td>0.21</td>\n",
              "      <td>6</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2595</td>\n",
              "      <td>Skylit Midtown Castle</td>\n",
              "      <td>2845</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Midtown</td>\n",
              "      <td>40.75362</td>\n",
              "      <td>-73.98377</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>225</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>2019-05-21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>2</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3647</td>\n",
              "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
              "      <td>4632</td>\n",
              "      <td>Elisabeth</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Harlem</td>\n",
              "      <td>40.80902</td>\n",
              "      <td>-73.94190</td>\n",
              "      <td>Private room</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3831</td>\n",
              "      <td>Cozy Entire Floor of Brownstone</td>\n",
              "      <td>4869</td>\n",
              "      <td>LisaRoxanne</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Clinton Hill</td>\n",
              "      <td>40.68514</td>\n",
              "      <td>-73.95976</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>2019-07-05</td>\n",
              "      <td>4.64</td>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5022</td>\n",
              "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
              "      <td>7192</td>\n",
              "      <td>Laura</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>East Harlem</td>\n",
              "      <td>40.79851</td>\n",
              "      <td>-73.94399</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>2018-11-19</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ... availability_365\n",
              "0  2539  ...              365\n",
              "1  2595  ...              355\n",
              "2  3647  ...              365\n",
              "3  3831  ...              194\n",
              "4  5022  ...                0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n90ileUR3T6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['neighbourhood_group'].replace(['Brooklyn', 'Manhattan', 'Queens', 'Staten Island', 'Bronx'],[0,1,2,3,4],inplace=True)\n",
        "train_df['room_type'].replace(['Private room', 'Entire home/apt', 'Shared room'],[0,1,2],inplace=True)\n",
        "train_df['reviews_per_month'].fillna(0, inplace = True)\n",
        "train_df['neighbourhood'].replace(['Kensington', 'Midtown', 'Harlem', 'Clinton Hill', 'East Harlem',\n",
        "       'Murray Hill', 'Bedford-Stuyvesant', \"Hell's Kitchen\",\n",
        "       'Upper West Side', 'Chinatown', 'South Slope', 'West Village',\n",
        "       'Williamsburg', 'Fort Greene', 'Chelsea', 'Crown Heights',\n",
        "       'Park Slope', 'Windsor Terrace', 'Inwood', 'East Village',\n",
        "       'Greenpoint', 'Bushwick', 'Flatbush', 'Lower East Side',\n",
        "       'Prospect-Lefferts Gardens', 'Long Island City', 'Kips Bay',\n",
        "       'SoHo', 'Upper East Side', 'Prospect Heights',\n",
        "       'Washington Heights', 'Woodside', 'Brooklyn Heights',\n",
        "       'Carroll Gardens', 'Gowanus', 'Flatlands', 'Cobble Hill',\n",
        "       'Flushing', 'Boerum Hill', 'Sunnyside', 'DUMBO', 'St. George',\n",
        "       'Highbridge', 'Financial District', 'Ridgewood',\n",
        "       'Morningside Heights', 'Jamaica', 'Middle Village', 'NoHo',\n",
        "       'Ditmars Steinway', 'Flatiron District', 'Roosevelt Island',\n",
        "       'Greenwich Village', 'Little Italy', 'East Flatbush',\n",
        "       'Tompkinsville', 'Astoria', 'Clason Point', 'Eastchester',\n",
        "       'Kingsbridge', 'Two Bridges', 'Queens Village', 'Rockaway Beach',\n",
        "       'Forest Hills', 'Nolita', 'Woodlawn', 'University Heights',\n",
        "       'Gravesend', 'Gramercy', 'Allerton', 'East New York',\n",
        "       'Theater District', 'Concourse Village', 'Sheepshead Bay',\n",
        "       'Emerson Hill', 'Fort Hamilton', 'Bensonhurst', 'Tribeca',\n",
        "       'Shore Acres', 'Sunset Park', 'Concourse', 'Elmhurst',\n",
        "       'Brighton Beach', 'Jackson Heights', 'Cypress Hills', 'St. Albans',\n",
        "       'Arrochar', 'Rego Park', 'Wakefield', 'Clifton', 'Bay Ridge',\n",
        "       'Graniteville', 'Spuyten Duyvil', 'Stapleton', 'Briarwood',\n",
        "       'Ozone Park', 'Columbia St', 'Vinegar Hill', 'Mott Haven',\n",
        "       'Longwood', 'Canarsie', 'Battery Park City', 'Civic Center',\n",
        "       'East Elmhurst', 'New Springville', 'Morris Heights', 'Arverne',\n",
        "       'Cambria Heights', 'Tottenville', 'Mariners Harbor', 'Concord',\n",
        "       'Borough Park', 'Bayside', 'Downtown Brooklyn', 'Port Morris',\n",
        "       'Fieldston', 'Kew Gardens', 'Midwood', 'College Point',\n",
        "       'Mount Eden', 'City Island', 'Glendale', 'Port Richmond',\n",
        "       'Red Hook', 'Richmond Hill', 'Bellerose', 'Maspeth',\n",
        "       'Williamsbridge', 'Soundview', 'Woodhaven', 'Woodrow',\n",
        "       'Co-op City', 'Stuyvesant Town', 'Parkchester', 'North Riverdale',\n",
        "       'Dyker Heights', 'Bronxdale', 'Sea Gate', 'Riverdale',\n",
        "       'Kew Gardens Hills', 'Bay Terrace', 'Norwood', 'Claremont Village',\n",
        "       'Whitestone', 'Fordham', 'Bayswater', 'Navy Yard', 'Brownsville',\n",
        "       'Eltingville', 'Fresh Meadows', 'Mount Hope', 'Lighthouse Hill',\n",
        "       'Springfield Gardens', 'Howard Beach', 'Belle Harbor',\n",
        "       'Jamaica Estates', 'Van Nest', 'Morris Park', 'West Brighton',\n",
        "       'Far Rockaway', 'South Ozone Park', 'Tremont', 'Corona',\n",
        "       'Great Kills', 'Manhattan Beach', 'Marble Hill', 'Dongan Hills',\n",
        "       'Castleton Corners', 'East Morrisania', 'Hunts Point', 'Neponsit',\n",
        "       'Pelham Bay', 'Randall Manor', 'Throgs Neck', 'Todt Hill',\n",
        "       'West Farms', 'Silver Lake', 'Morrisania', 'Laurelton',\n",
        "       'Grymes Hill', 'Holliswood', 'Pelham Gardens', 'Belmont',\n",
        "       'Rosedale', 'Edgemere', 'New Brighton', 'Midland Beach',\n",
        "       'Baychester', 'Melrose', 'Bergen Beach', 'Richmondtown',\n",
        "       'Howland Hook', 'Schuylerville', 'Coney Island', 'New Dorp Beach',\n",
        "       \"Prince's Bay\", 'South Beach', 'Bath Beach', 'Jamaica Hills',\n",
        "       'Oakwood', 'Castle Hill', 'Hollis', 'Douglaston', 'Huguenot',\n",
        "       'Olinville', 'Edenwald', 'Grant City', 'Westerleigh',\n",
        "       'Bay Terrace, Staten Island', 'Westchester Square', 'Little Neck',\n",
        "       'Fort Wadsworth', 'Rosebank', 'Unionport', 'Mill Basin',\n",
        "       'Arden Heights', \"Bull's Head\", 'New Dorp', 'Rossville',\n",
        "       'Breezy Point', 'Willowbrook'],[i for i in range(221)], inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcDxdcAc3Zyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.drop(['id','name','host_id','latitude','longitude','host_name','last_review'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW7zC8Ml4fTR",
        "colab_type": "code",
        "outputId": "b813b47f-21d4-4d5b-fe82-7785d5071fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_df\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>neighbourhood_group</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>room_type</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0.21</td>\n",
              "      <td>6</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>225</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>0.38</td>\n",
              "      <td>2</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>4.64</td>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>3</td>\n",
              "      <td>74</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>45</td>\n",
              "      <td>49</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>2</td>\n",
              "      <td>430</td>\n",
              "      <td>3.47</td>\n",
              "      <td>1</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>2</td>\n",
              "      <td>118</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1.33</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>5</td>\n",
              "      <td>53</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>2</td>\n",
              "      <td>188</td>\n",
              "      <td>1.50</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>4</td>\n",
              "      <td>167</td>\n",
              "      <td>1.34</td>\n",
              "      <td>3</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>2</td>\n",
              "      <td>113</td>\n",
              "      <td>0.91</td>\n",
              "      <td>1</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>90</td>\n",
              "      <td>27</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>2</td>\n",
              "      <td>148</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>215</td>\n",
              "      <td>2</td>\n",
              "      <td>198</td>\n",
              "      <td>1.72</td>\n",
              "      <td>1</td>\n",
              "      <td>321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "      <td>260</td>\n",
              "      <td>2.12</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>3</td>\n",
              "      <td>53</td>\n",
              "      <td>4.44</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>190</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>299</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>1.09</td>\n",
              "      <td>6</td>\n",
              "      <td>347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0.37</td>\n",
              "      <td>6</td>\n",
              "      <td>364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>2</td>\n",
              "      <td>71</td>\n",
              "      <td>0.61</td>\n",
              "      <td>6</td>\n",
              "      <td>304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>2</td>\n",
              "      <td>88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>2</td>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1.37</td>\n",
              "      <td>2</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>150</td>\n",
              "      <td>10</td>\n",
              "      <td>58</td>\n",
              "      <td>0.49</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>3</td>\n",
              "      <td>108</td>\n",
              "      <td>1.11</td>\n",
              "      <td>3</td>\n",
              "      <td>311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>180</td>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48865</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48866</th>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48867</th>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6</td>\n",
              "      <td>338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48868</th>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48869</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48870</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48871</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48872</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>260</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48873</th>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48874</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48875</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48876</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48877</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48878</th>\n",
              "      <td>2</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48879</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48880</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48881</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48882</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48883</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48884</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48885</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48886</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48887</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48888</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48889</th>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48890</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48891</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48892</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48893</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48894</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48895 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       neighbourhood_group  ...  availability_365\n",
              "0                        0  ...               365\n",
              "1                        1  ...               355\n",
              "2                        1  ...               365\n",
              "3                        0  ...               194\n",
              "4                        1  ...                 0\n",
              "5                        1  ...               129\n",
              "6                        0  ...                 0\n",
              "7                        1  ...               220\n",
              "8                        1  ...                 0\n",
              "9                        1  ...               188\n",
              "10                       1  ...                 6\n",
              "11                       1  ...                39\n",
              "12                       0  ...               314\n",
              "13                       1  ...               333\n",
              "14                       1  ...                 0\n",
              "15                       0  ...                46\n",
              "16                       0  ...               321\n",
              "17                       1  ...                12\n",
              "18                       0  ...                21\n",
              "19                       1  ...               249\n",
              "20                       0  ...                 0\n",
              "21                       0  ...               347\n",
              "22                       0  ...               364\n",
              "23                       0  ...               304\n",
              "24                       0  ...               233\n",
              "25                       0  ...                85\n",
              "26                       1  ...                 0\n",
              "27                       1  ...                75\n",
              "28                       1  ...               311\n",
              "29                       1  ...                67\n",
              "...                    ...  ...               ...\n",
              "48865                    1  ...                79\n",
              "48866                    2  ...               159\n",
              "48867                    0  ...               338\n",
              "48868                    0  ...               365\n",
              "48869                    0  ...                 7\n",
              "48870                    0  ...                22\n",
              "48871                    1  ...                31\n",
              "48872                    1  ...                 9\n",
              "48873                    0  ...               363\n",
              "48874                    1  ...                22\n",
              "48875                    1  ...               180\n",
              "48876                    1  ...                26\n",
              "48877                    0  ...                16\n",
              "48878                    2  ...               172\n",
              "48879                    0  ...                22\n",
              "48880                    0  ...               365\n",
              "48881                    0  ...                15\n",
              "48882                    0  ...                31\n",
              "48883                    1  ...               364\n",
              "48884                    0  ...               341\n",
              "48885                    1  ...               353\n",
              "48886                    1  ...               176\n",
              "48887                    0  ...               365\n",
              "48888                    1  ...                31\n",
              "48889                    2  ...               163\n",
              "48890                    0  ...                 9\n",
              "48891                    0  ...                36\n",
              "48892                    1  ...                27\n",
              "48893                    1  ...                 2\n",
              "48894                    1  ...                23\n",
              "\n",
              "[48895 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUXDk4gM3wQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keSkeeK05cTg",
        "colab_type": "code",
        "outputId": "80883e26-a2ff-49d1-8864-dd8490d1c53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        " \n",
        "def create_mlp(dim, regress=False):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
        "  model.add(Dense(4, activation=\"relu\"))\n",
        "  if regress:\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0_-buQd5peu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27UGUmfw6Bxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train, test) = train_test_split(train_df, test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUI8Knv66Ktk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxPrice = train['price'].max()\n",
        "trainY = train['price'] / maxPrice\n",
        "testY = test['price'] / maxPrice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjR0oP4r612N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "trainContinuous = scaler.fit_transform(train)\n",
        "testContinuous = scaler.fit_transform(test)\n",
        "train1 = train['price']\n",
        "test1 = test['price']\n",
        "train2 = train1.values.reshape(-1,1)\n",
        "test2 = test1.values.reshape(-1,1)\n",
        "trainCategorical = scaler.fit_transform(train2)\n",
        "testCategorical = scaler.fit_transform(test2)\n",
        "trainX = np.hstack([trainCategorical, trainContinuous])\n",
        "testX = np.hstack([testCategorical, testContinuous])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSk5tNwn68T9",
        "colab_type": "code",
        "outputId": "3dbdf120-0411-4da0-ec76-858c4243a5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = create_mlp(trainX.shape[1], regress=True)\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
        " \n",
        "print(\"Training model...\")\n",
        "model.fit(trainX, trainY, validation_data=(testX, testY),\n",
        "\tepochs=200, batch_size=8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 36671 samples, validate on 12224 samples\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "36671/36671 [==============================] - 6s 170us/step - loss: 2282.9994 - val_loss: 2237.3501\n",
            "Epoch 2/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 2107.6821 - val_loss: 4724.4590\n",
            "Epoch 3/200\n",
            "36671/36671 [==============================] - 6s 169us/step - loss: 2998.2465 - val_loss: 1403.1360\n",
            "Epoch 4/200\n",
            "36671/36671 [==============================] - 6s 163us/step - loss: 2110.1718 - val_loss: 1969.0786\n",
            "Epoch 5/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 2035.4006 - val_loss: 2052.5001\n",
            "Epoch 6/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 4370.1163 - val_loss: 559.5652\n",
            "Epoch 7/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 2417.8271 - val_loss: 1641.2560\n",
            "Epoch 8/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 3113.9492 - val_loss: 2337.2463\n",
            "Epoch 9/200\n",
            "36671/36671 [==============================] - 6s 158us/step - loss: 2411.0353 - val_loss: 59.7492\n",
            "Epoch 10/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 2200.9487 - val_loss: 2122.8324\n",
            "Epoch 11/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 2291.0106 - val_loss: 1399.9503\n",
            "Epoch 12/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 2077.2156 - val_loss: 2650.1753\n",
            "Epoch 13/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 2732.0139 - val_loss: 550.1476\n",
            "Epoch 14/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 2608.7536 - val_loss: 1454.1934\n",
            "Epoch 15/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1893.4252 - val_loss: 1267.2995\n",
            "Epoch 16/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1508.9243 - val_loss: 1750.6403\n",
            "Epoch 17/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 2448.2252 - val_loss: 704.6954\n",
            "Epoch 18/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 2199.8761 - val_loss: 1735.3083\n",
            "Epoch 19/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1969.9672 - val_loss: 127.2460\n",
            "Epoch 20/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1675.2393 - val_loss: 572.7845\n",
            "Epoch 21/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1847.7411 - val_loss: 580.2492\n",
            "Epoch 22/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 2008.7926 - val_loss: 3243.8747\n",
            "Epoch 23/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 2247.7602 - val_loss: 310.8298\n",
            "Epoch 24/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 2255.2205 - val_loss: 760.8353\n",
            "Epoch 25/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 1554.7499 - val_loss: 3518.2550\n",
            "Epoch 26/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 1991.6807 - val_loss: 279.6138\n",
            "Epoch 27/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 1518.4414 - val_loss: 1557.3393\n",
            "Epoch 28/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 2148.7553 - val_loss: 1607.3829\n",
            "Epoch 29/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1569.0204 - val_loss: 2106.0410\n",
            "Epoch 30/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 1613.4512 - val_loss: 530.6901\n",
            "Epoch 31/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 1511.2279 - val_loss: 720.2719\n",
            "Epoch 32/200\n",
            "36671/36671 [==============================] - 6s 158us/step - loss: 1766.2002 - val_loss: 696.6515\n",
            "Epoch 33/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 2028.4271 - val_loss: 1795.7456\n",
            "Epoch 34/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1671.4059 - val_loss: 598.1933\n",
            "Epoch 35/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1210.7826 - val_loss: 1988.5760\n",
            "Epoch 36/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1445.9485 - val_loss: 267.2139\n",
            "Epoch 37/200\n",
            "36671/36671 [==============================] - 6s 159us/step - loss: 1947.6782 - val_loss: 1520.9732\n",
            "Epoch 38/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 1502.1869 - val_loss: 1056.1657\n",
            "Epoch 39/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1340.5814 - val_loss: 503.4624\n",
            "Epoch 40/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 1444.8168 - val_loss: 834.8303\n",
            "Epoch 41/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 1527.5026 - val_loss: 636.4507\n",
            "Epoch 42/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1382.3126 - val_loss: 916.6760\n",
            "Epoch 43/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1114.1357 - val_loss: 1536.3159\n",
            "Epoch 44/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1450.0770 - val_loss: 152.0372\n",
            "Epoch 45/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1166.9516 - val_loss: 1442.2292\n",
            "Epoch 46/200\n",
            "36671/36671 [==============================] - 6s 159us/step - loss: 1453.0890 - val_loss: 1334.9773\n",
            "Epoch 47/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1531.2028 - val_loss: 738.9966\n",
            "Epoch 48/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 1476.9285 - val_loss: 276.3355\n",
            "Epoch 49/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 1537.0557 - val_loss: 1330.2964\n",
            "Epoch 50/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1696.9974 - val_loss: 386.8999\n",
            "Epoch 51/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1429.5891 - val_loss: 1478.0012\n",
            "Epoch 52/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 1564.3691 - val_loss: 258.4202\n",
            "Epoch 53/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1294.0246 - val_loss: 1145.3471\n",
            "Epoch 54/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 1278.3944 - val_loss: 122.3090\n",
            "Epoch 55/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 975.6600 - val_loss: 1588.9292\n",
            "Epoch 56/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1027.4362 - val_loss: 426.2747\n",
            "Epoch 57/200\n",
            "36671/36671 [==============================] - 6s 160us/step - loss: 1039.2717 - val_loss: 1464.4367\n",
            "Epoch 58/200\n",
            "36671/36671 [==============================] - 6s 168us/step - loss: 1133.6831 - val_loss: 755.2639\n",
            "Epoch 59/200\n",
            "36671/36671 [==============================] - 6s 159us/step - loss: 1180.8769 - val_loss: 120.4692\n",
            "Epoch 60/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1091.1563 - val_loss: 1317.0498\n",
            "Epoch 61/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 1491.0150 - val_loss: 689.6502\n",
            "Epoch 62/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 939.8374 - val_loss: 1267.5878\n",
            "Epoch 63/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1223.6729 - val_loss: 185.2047\n",
            "Epoch 64/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 808.8096 - val_loss: 1624.6007\n",
            "Epoch 65/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 859.9456 - val_loss: 544.8423\n",
            "Epoch 66/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 2178.9454 - val_loss: 685.4217\n",
            "Epoch 67/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1598.2587 - val_loss: 1174.3582\n",
            "Epoch 68/200\n",
            "36671/36671 [==============================] - 6s 159us/step - loss: 1482.6459 - val_loss: 446.5549\n",
            "Epoch 69/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1060.6968 - val_loss: 1343.7384\n",
            "Epoch 70/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1447.8378 - val_loss: 740.6944\n",
            "Epoch 71/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1058.7810 - val_loss: 851.1634\n",
            "Epoch 72/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1077.6730 - val_loss: 1015.1401\n",
            "Epoch 73/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 1145.5845 - val_loss: 352.3110\n",
            "Epoch 74/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 953.3907 - val_loss: 931.3060\n",
            "Epoch 75/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 2076.4733 - val_loss: 294.6317\n",
            "Epoch 76/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1637.7984 - val_loss: 1071.9958\n",
            "Epoch 77/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1792.0770 - val_loss: 470.8690\n",
            "Epoch 78/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1265.6262 - val_loss: 1164.3261\n",
            "Epoch 79/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 1064.1898 - val_loss: 722.0975\n",
            "Epoch 80/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1318.2068 - val_loss: 1095.0579\n",
            "Epoch 81/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 1247.2554 - val_loss: 1180.6012\n",
            "Epoch 82/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 1039.0493 - val_loss: 304.4512\n",
            "Epoch 83/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 986.0858 - val_loss: 1264.9723\n",
            "Epoch 84/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 895.3313 - val_loss: 152.7065\n",
            "Epoch 85/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 964.8862 - val_loss: 1086.7240\n",
            "Epoch 86/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1141.6540 - val_loss: 172.9376\n",
            "Epoch 87/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 916.3874 - val_loss: 835.2708\n",
            "Epoch 88/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 909.1482 - val_loss: 607.3380\n",
            "Epoch 89/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 901.8144 - val_loss: 297.3388\n",
            "Epoch 90/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 1221.2650 - val_loss: 903.2134\n",
            "Epoch 91/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 1051.7210 - val_loss: 140.0606\n",
            "Epoch 92/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 856.7483 - val_loss: 638.8936\n",
            "Epoch 93/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 981.2089 - val_loss: 1107.7189\n",
            "Epoch 94/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 1214.6439 - val_loss: 382.8547\n",
            "Epoch 95/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 839.0843 - val_loss: 710.5774\n",
            "Epoch 96/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 991.6557 - val_loss: 457.9888\n",
            "Epoch 97/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 822.1893 - val_loss: 160.8168\n",
            "Epoch 98/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 802.6863 - val_loss: 1189.0675\n",
            "Epoch 99/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 1005.6970 - val_loss: 547.3028\n",
            "Epoch 100/200\n",
            "36671/36671 [==============================] - 6s 163us/step - loss: 967.5130 - val_loss: 938.3442\n",
            "Epoch 101/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 839.2179 - val_loss: 289.4413\n",
            "Epoch 102/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 876.7376 - val_loss: 820.7638\n",
            "Epoch 103/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 738.4531 - val_loss: 723.9416\n",
            "Epoch 104/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 762.4854 - val_loss: 988.5084\n",
            "Epoch 105/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 929.1829 - val_loss: 112.3247\n",
            "Epoch 106/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 816.7107 - val_loss: 353.6728\n",
            "Epoch 107/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 794.6741 - val_loss: 796.1183\n",
            "Epoch 108/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 947.4749 - val_loss: 413.7947\n",
            "Epoch 109/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 716.1279 - val_loss: 520.7975\n",
            "Epoch 110/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 668.8483 - val_loss: 363.5744\n",
            "Epoch 111/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 739.0199 - val_loss: 689.3085\n",
            "Epoch 112/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 755.9208 - val_loss: 342.6996\n",
            "Epoch 113/200\n",
            "36671/36671 [==============================] - 6s 169us/step - loss: 794.1986 - val_loss: 360.2151\n",
            "Epoch 114/200\n",
            "36671/36671 [==============================] - 6s 162us/step - loss: 731.0706 - val_loss: 689.6673\n",
            "Epoch 115/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 820.5645 - val_loss: 187.8048\n",
            "Epoch 116/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 623.8883 - val_loss: 798.2132\n",
            "Epoch 117/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 719.4761 - val_loss: 176.5037\n",
            "Epoch 118/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 659.9500 - val_loss: 936.4532\n",
            "Epoch 119/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 769.2156 - val_loss: 170.5629\n",
            "Epoch 120/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 690.2522 - val_loss: 326.2449\n",
            "Epoch 121/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 646.7555 - val_loss: 816.2772\n",
            "Epoch 122/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 654.2652 - val_loss: 540.3090\n",
            "Epoch 123/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 657.3218 - val_loss: 220.1943\n",
            "Epoch 124/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 753.5349 - val_loss: 241.7238\n",
            "Epoch 125/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 772.3953 - val_loss: 144.4651\n",
            "Epoch 126/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 575.2602 - val_loss: 730.5271\n",
            "Epoch 127/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 799.9736 - val_loss: 179.2022\n",
            "Epoch 128/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 661.6499 - val_loss: 183.5764\n",
            "Epoch 129/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 620.3756 - val_loss: 637.8637\n",
            "Epoch 130/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 620.8346 - val_loss: 483.7677\n",
            "Epoch 131/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 610.8772 - val_loss: 500.1428\n",
            "Epoch 132/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 683.6460 - val_loss: 867.6795\n",
            "Epoch 133/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 662.3204 - val_loss: 280.4397\n",
            "Epoch 134/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 465.8585 - val_loss: 547.3016\n",
            "Epoch 135/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 821.5406 - val_loss: 18.6681\n",
            "Epoch 136/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 460.5891 - val_loss: 751.4512\n",
            "Epoch 137/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 534.1987 - val_loss: 242.7964\n",
            "Epoch 138/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 621.0029 - val_loss: 1065.8868\n",
            "Epoch 139/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 694.6974 - val_loss: 287.9006\n",
            "Epoch 140/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 665.8245 - val_loss: 627.8362\n",
            "Epoch 141/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 671.2816 - val_loss: 247.0613\n",
            "Epoch 142/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 638.6444 - val_loss: 187.6361\n",
            "Epoch 143/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 740.7887 - val_loss: 221.3378\n",
            "Epoch 144/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 575.4853 - val_loss: 589.3775\n",
            "Epoch 145/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 707.1702 - val_loss: 598.1613\n",
            "Epoch 146/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 663.0051 - val_loss: 669.0299\n",
            "Epoch 147/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 652.8266 - val_loss: 125.9344\n",
            "Epoch 148/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 562.5480 - val_loss: 517.3611\n",
            "Epoch 149/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 615.7401 - val_loss: 132.6783\n",
            "Epoch 150/200\n",
            "36671/36671 [==============================] - 6s 150us/step - loss: 426.1172 - val_loss: 783.9046\n",
            "Epoch 151/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 834.2643 - val_loss: 179.9874\n",
            "Epoch 152/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 666.3456 - val_loss: 1099.2603\n",
            "Epoch 153/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 733.1763 - val_loss: 116.1849\n",
            "Epoch 154/200\n",
            "36671/36671 [==============================] - 6s 159us/step - loss: 688.7314 - val_loss: 1155.9155\n",
            "Epoch 155/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 913.0435 - val_loss: 224.7410\n",
            "Epoch 156/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 770.9148 - val_loss: 657.7446\n",
            "Epoch 157/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 629.9767 - val_loss: 261.6124\n",
            "Epoch 158/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 734.4193 - val_loss: 387.0898\n",
            "Epoch 159/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 635.0248 - val_loss: 279.1936\n",
            "Epoch 160/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 639.0352 - val_loss: 1116.1063\n",
            "Epoch 161/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 722.8647 - val_loss: 174.2123\n",
            "Epoch 162/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 581.3988 - val_loss: 217.2220\n",
            "Epoch 163/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 595.1384 - val_loss: 344.3887\n",
            "Epoch 164/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 469.7031 - val_loss: 360.6246\n",
            "Epoch 165/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 588.0854 - val_loss: 586.7203\n",
            "Epoch 166/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 637.2740 - val_loss: 99.1671\n",
            "Epoch 167/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 445.0195 - val_loss: 1001.3486\n",
            "Epoch 168/200\n",
            "36671/36671 [==============================] - 6s 166us/step - loss: 619.5567 - val_loss: 60.3804\n",
            "Epoch 169/200\n",
            "36671/36671 [==============================] - 6s 164us/step - loss: 475.8196 - val_loss: 397.2172\n",
            "Epoch 170/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 528.0737 - val_loss: 318.8871\n",
            "Epoch 171/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 428.0850 - val_loss: 363.1783\n",
            "Epoch 172/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 516.1949 - val_loss: 746.6197\n",
            "Epoch 173/200\n",
            "36671/36671 [==============================] - 6s 157us/step - loss: 657.9321 - val_loss: 356.5027\n",
            "Epoch 174/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 537.6114 - val_loss: 81.5962\n",
            "Epoch 175/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 483.8722 - val_loss: 675.1821\n",
            "Epoch 176/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 564.3044 - val_loss: 330.3334\n",
            "Epoch 177/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 416.5030 - val_loss: 228.2954\n",
            "Epoch 178/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 475.9831 - val_loss: 159.2783\n",
            "Epoch 179/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 495.4745 - val_loss: 745.7690\n",
            "Epoch 180/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 467.2481 - val_loss: 208.7774\n",
            "Epoch 181/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 801.8019 - val_loss: 127.8820\n",
            "Epoch 182/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 718.0542 - val_loss: 384.7146\n",
            "Epoch 183/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 493.3764 - val_loss: 293.3593\n",
            "Epoch 184/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 485.4061 - val_loss: 158.3035\n",
            "Epoch 185/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 466.0358 - val_loss: 472.1584\n",
            "Epoch 186/200\n",
            "36671/36671 [==============================] - 6s 151us/step - loss: 590.9086 - val_loss: 206.0933\n",
            "Epoch 187/200\n",
            "36671/36671 [==============================] - 6s 153us/step - loss: 531.5312 - val_loss: 559.6936\n",
            "Epoch 188/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 590.7236 - val_loss: 63.6165\n",
            "Epoch 189/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 587.5848 - val_loss: 478.7950\n",
            "Epoch 190/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 531.3790 - val_loss: 283.4202\n",
            "Epoch 191/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 570.0576 - val_loss: 309.9465\n",
            "Epoch 192/200\n",
            "36671/36671 [==============================] - 6s 159us/step - loss: 652.3207 - val_loss: 445.1205\n",
            "Epoch 193/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 578.1556 - val_loss: 240.4860\n",
            "Epoch 194/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 461.0993 - val_loss: 521.6776\n",
            "Epoch 195/200\n",
            "36671/36671 [==============================] - 6s 154us/step - loss: 480.2570 - val_loss: 131.1172\n",
            "Epoch 196/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 485.6882 - val_loss: 403.2156\n",
            "Epoch 197/200\n",
            "36671/36671 [==============================] - 6s 152us/step - loss: 439.3145 - val_loss: 62.8647\n",
            "Epoch 198/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 455.5246 - val_loss: 319.6505\n",
            "Epoch 199/200\n",
            "36671/36671 [==============================] - 6s 156us/step - loss: 534.9917 - val_loss: 269.1976\n",
            "Epoch 200/200\n",
            "36671/36671 [==============================] - 6s 155us/step - loss: 515.7920 - val_loss: 219.7545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7facb80dbf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqaxKWvQ7EnU",
        "colab_type": "code",
        "outputId": "8336840d-3aad-4b90-8ce4-faa6fe5fc076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "prediction = model.predict(testX)\n",
        "print(\"Valuation for first 20 rows..\")\n",
        "for i in range(20):\n",
        "  y_0 = prediction[i][0]\n",
        "  y_0 *= 10000\n",
        "  print(\"AirBnb Property Prediction  - ${}\".format(y_0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automated Valuation for rows..\n",
            "AirBnb Property Prediction  - $74.84195288270712\n",
            "AirBnb Property Prediction  - $22.735707461833954\n",
            "AirBnb Property Prediction  - $102.58428752422333\n",
            "AirBnb Property Prediction  - $352.68720239400864\n",
            "AirBnb Property Prediction  - $157.22284093499184\n",
            "AirBnb Property Prediction  - $135.609433054924\n",
            "AirBnb Property Prediction  - $81.4594142138958\n",
            "AirBnb Property Prediction  - $55.301920510828495\n",
            "AirBnb Property Prediction  - $120.55186554789543\n",
            "AirBnb Property Prediction  - $64.55449853092432\n",
            "AirBnb Property Prediction  - $16.78232685662806\n",
            "AirBnb Property Prediction  - $160.25368124246597\n",
            "AirBnb Property Prediction  - $180.95795065164566\n",
            "AirBnb Property Prediction  - $42.7189702168107\n",
            "AirBnb Property Prediction  - $85.52375249564648\n",
            "AirBnb Property Prediction  - $89.10888805985451\n",
            "AirBnb Property Prediction  - $95.11781856417656\n",
            "AirBnb Property Prediction  - $83.84746499359608\n",
            "AirBnb Property Prediction  - $103.13782840967178\n",
            "AirBnb Property Prediction  - $184.57097932696342\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}